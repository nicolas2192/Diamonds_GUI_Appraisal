{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train = pd.read_csv('../data/raw/diamonds_train.csv')\n",
    "test = pd.read_csv('../data/raw/diamonds_test.csv')\n",
    "full = pd.read_csv('../data/raw/diamonds.csv')\n",
    "single = pd.read_csv('../data/raw/single_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns\n",
    "NUM_FEATS = ['x', 'y', 'z', 'depth', 'table', 'carat']\n",
    "CAT_FEATS = ['cut', 'color', 'clarity']\n",
    "ALL_FEATS = NUM_FEATS + CAT_FEATS\n",
    "TARGET = 'price'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer. Previous tasks we apply to our columns to make the model more accurate\n",
    "transformer = ColumnTransformer(transformers=[(\"scaler\", RobustScaler(), NUM_FEATS), \n",
    "                                              (\"encoder\", OneHotEncoder(), CAT_FEATS)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53939, 11)\n",
      "(1, 11)\n"
     ]
    }
   ],
   "source": [
    "# Split the data to train the model and test it later\n",
    "X_train, X_test = train_test_split(full, test_size=0.000001)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the pipeline, what to do before the training and the model to train\n",
    "pipe = Pipeline(steps=[(\"transformer\", transformer),\n",
    "                       (\"model\", RandomForestRegressor(n_estimators=512, max_depth=16))], verbose=10)\n",
    "# pipe = Pipeline(steps=[(\"transformer\", transformer),\n",
    "#                        (\"pca\", PCA(0.95)),\n",
    "#                        (\"model\", GradientBoostingRegressor())], verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ....... (step 1 of 2) Processing transformer, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total= 2.7min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('transformer',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('scaler',\n",
       "                                                  RobustScaler(copy=True,\n",
       "                                                               quantile_range=(25.0,\n",
       "                                                                               75.0),\n",
       "                                                               with_centering=True,\n",
       "                                                               with_scaling=True),\n",
       "                                                  ['x', 'y', 'z', 'depth',\n",
       "                                                   'table', 'carat']),\n",
       "                                                 ('encoder',\n",
       "                                                  OneHotEncoder(categories='auto',\n",
       "                                                                drop=None,\n",
       "                                                                dtype=<cl...\n",
       "                 RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
       "                                       criterion='mse', max_depth=16,\n",
       "                                       max_features='auto', max_leaf_nodes=None,\n",
       "                                       max_samples=None,\n",
       "                                       min_impurity_decrease=0.0,\n",
       "                                       min_impurity_split=None,\n",
       "                                       min_samples_leaf=1, min_samples_split=2,\n",
       "                                       min_weight_fraction_leaf=0.0,\n",
       "                                       n_estimators=512, n_jobs=None,\n",
       "                                       oob_score=False, random_state=None,\n",
       "                                       verbose=0, warm_start=False))],\n",
       "         verbose=10)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model using pipeline\n",
    "pipe.fit(X_train[ALL_FEATS], X_train[TARGET])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error: 16.23772637488537\n",
      "train error: 311.8462666595142\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolas/miniconda3/envs/labs_env/lib/python3.7/site-packages/sklearn/metrics/_regression.py:582: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    }
   ],
   "source": [
    "# Predicting our y_test using X_test previously split from the main dataframe\n",
    "y_test = pipe.predict(X_test[ALL_FEATS])\n",
    "y_train = pipe.predict(X_train[ALL_FEATS])\n",
    "# Calculate rmse for both, test and train previously split\n",
    "rmse_test = mean_squared_error(y_pred=y_test, y_true=X_test[TARGET], squared=False)\n",
    "rmse_train = mean_squared_error(y_pred=y_train, y_true=X_train[TARGET], squared=False)\n",
    "r2 = r2_score(y_pred=y_test, y_true=X_test[TARGET])\n",
    "print(f\"test error: {rmse_test}\") # 786.32708700068 -> best 521.233209489903\n",
    "print(f\"train error: {rmse_train}\") # 708.453678764242 -> best 301.637420203425\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  2.0min remaining:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  2.0min remaining:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "557.8155155759545"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross validation, checking results\n",
    "scores = cross_val_score(pipe, train[ALL_FEATS], train[TARGET], \n",
    "                         scoring='neg_root_mean_squared_error', cv=5, n_jobs=-1, verbose=10)\n",
    "np.mean(-scores) # 733.2874856161409 ->  best 557.9761591423182"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model Optimization, Grid Search\n",
    "# param = {\"model__n_estimators\" : [16, 32, 64, 128, 256, 512], 'model__max_depth': [2, 4, 8, 16]}\n",
    "# tuned_pipe = GridSearchCV(pipe, param, cv=10, verbose=10, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "# tuned_pipe.fit(X_train[ALL_FEATS], X_train[TARGET])\n",
    "# tuned_pipe.best_params_ {'model__max_depth': 16, 'model__n_estimators': 512}\n",
    "# tuned_pipe.best_score_ -556.4260213207206"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2925.93459031, 5586.35317625, 9404.72807476, ..., 3000.87129602,\n",
       "       2104.43953844,  817.78758568])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting new data\n",
    "# y_new_data = tuned_pipe.predict(test[ALL_FEATS]) # GridSearch\n",
    "y_new_data = pipe.predict(test[ALL_FEATS])\n",
    "# y_new_data = pipe.predict(single[ALL_FEATS]) # 2976.18647031\n",
    "y_new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13485.000000</td>\n",
       "      <td>13485.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6742.000000</td>\n",
       "      <td>3948.029452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3892.928525</td>\n",
       "      <td>3954.073616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>364.672886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3371.000000</td>\n",
       "      <td>942.128646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6742.000000</td>\n",
       "      <td>2438.755571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10113.000000</td>\n",
       "      <td>5296.411988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13484.000000</td>\n",
       "      <td>18397.171484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id         price\n",
       "count  13485.000000  13485.000000\n",
       "mean    6742.000000   3948.029452\n",
       "std     3892.928525   3954.073616\n",
       "min        0.000000    364.672886\n",
       "25%     3371.000000    942.128646\n",
       "50%     6742.000000   2438.755571\n",
       "75%    10113.000000   5296.411988\n",
       "max    13484.000000  18397.171484"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.DataFrame({\"id\": test.index, \"price\": y_new_data})\n",
    "sub.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub[\"price\"].clip(lower=300, upper=20000, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"../data/submission/sub_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:labs_env]",
   "language": "python",
   "name": "conda-env-labs_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
